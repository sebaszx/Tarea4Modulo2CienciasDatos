{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarea4_parte1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebaszx/Tarea4Modulo2CienciasDatos/blob/main/Tarea4_parte1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 4**. Integrantes: Luis Vargas, Sebastián Porras"
      ],
      "metadata": {
        "id": "Xp7iWDjisMmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOLO\n",
        "\n",
        "##¿Qué es YOLO? \n",
        "Es una familia de algoritmos de **detección de objetos** basada en aprendizaje profundo.\n",
        "\n",
        "Al utilizar modelos de regresión, son sumamente rápidos.\n",
        "\n",
        "Su nombre se deriva de *You Only Look Once*, en referencia a que opera con una sola propagación hacia adelante.\n",
        "\n",
        "A partir de una imagen, los algoritmos de detección de objetos buscan dar respuesta a las siguientes preguntas:\n",
        "\n",
        "**¿Dónde está localizado el objeto** (sección de la imagen)\n",
        "\n",
        "**¿Cuál es su dimensión?**  (cajas de contorno)\n",
        "\n",
        "**¿Qué tipo de objeto es?** (clase, etiquetas)\n",
        "\n",
        "##Algoritmos de detección de objetos basados en aprendizaje profundo\n",
        "\n",
        "Los algoritmos de detección de objetos que operan con aprendizaje profundo pueden estar basados en **modelos de clasificación o regresión**.\n",
        "\n",
        "Los modelos de **clasificación**, como la CNNs basadas en regiones (R-CNNs), involucran dos pasos, lo cual alenta el proceso e incrementa el costo computacional:\n",
        "\n",
        "- identificar una serie de regiones de interés (ROI)\n",
        "- aplicar CNN (el 'detector') a todas las ROI para detectar la presencia de objetos\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/R-CNN.JPG'>\n",
        "\n",
        "**Figura 1.** Pasos del procesamiento de imágenes con R-CNN\n",
        "\n",
        "En constraste, los modelos de **regresión** predicen las cajas de contorno y las etiquetas directamente a partir de la imagen completa, por lo que tienen mayor velocidad. YOLO pertenece a este último tipo de algoritmos."
      ],
      "metadata": {
        "id": "9gXaVeNmVruH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##YOLO: ¿cómo funciona? ¿en qué consiste?\n",
        "\n",
        "En YOLO una sola red convolucional predice las cajas de contorno y las probabilidades de las clases para cada una.\n",
        "\n",
        "Pasos:\n",
        "\n",
        "- Una imagen se divide en una cuadrícula $SxS$\n",
        "- Se determinan $m$ cajas de contorno\n",
        "- La red CNN predice probabilidades de clase y valores de compensación para cada caja\n",
        "- Las cajas cuyas probabilidades superan un umbral de detección son utilizadas para localizar el objeto en la imagen\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/YOLOv1_arquitectura.JPG'>\n",
        "\n",
        "**Figura 2.** La arquitectura de YOLOv1 tiene 24 capas convolucionales seguidas de 2 capas totalmente concetadas (fully connected layers).\n",
        "\n",
        "###Ventaja\n",
        "YOLO puede ser órdenes de magnitud más rápido (hasta 45 recuadros por segundo) que otros algoritmos de detección\n",
        "\n",
        "###Desventaja\n",
        "Desempeño limitado con objetos relativamente pequeños"
      ],
      "metadata": {
        "id": "9P9fEdTdhMiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/YOLO_steps.JPG'>\n",
        "\n",
        "**Figura 3.** Pasos durante el procesamiento de imágenes con YOLO"
      ],
      "metadata": {
        "id": "xQXLZK8wv5SP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/Yolov3_cajas.JPG'>\n",
        "\n",
        "**Figura 4.** Cajas de contorno (*bounding boxes*) con predicción de la ubicación, YOLOv3."
      ],
      "metadata": {
        "id": "FiWgbez1vfY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Historia de YOLO\n",
        "\n",
        "Han surgido 5 versiones, sus respectivas fechas de publicación y enlaces a las referencias se detallan a continuación:\n",
        "\n",
        "[YOLOv1](https://https://arxiv.org/abs/1506.02640) (2015): You Only Look Once: Unified, Real-Time Object Detection\n",
        "\n",
        "[YOLOv2](https://https://arxiv.org/abs/1612.08242v1) (2016): YOLO9000: Better, Faster, Stronger\n",
        "\n",
        "**[YOLOv3](https://https://arxiv.org/abs/1804.02767v1) (2018): YOLOv3: An Incremental Improvement**. - Esta es la versión que usaremos en la presente demostración\n",
        "\n",
        "[YOLOv4](https://arxiv.org/abs/2004.10934v1) (2020): YOLOv4: Optimal Speed and Accuracy of Object Detection\n",
        "\n",
        "YOLOv5 (2020): cuenta con un repositorio en [Github](https://https://github.com/ultralytics/yolov5), pero no parece estar respaldado por una publicación científica aún ([ver comentarios](https://https://github.com/ultralytics/yolov5/issues/1333))\n",
        "\n"
      ],
      "metadata": {
        "id": "4poxIrfIQSk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ejemplo\n",
        "<img src='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/Detected with YOLO_MTheiler_(CC BY-SA 4.0).jpg'>\n",
        "\n",
        "**Figura 5.** Imagen procesada con el algoritmo YOLOv3 entrenado usando el conjunto de datos COCO, capaza de detectar 80 objectos comunes en contexto. Fuente de imagen: MTheiler (CC BY-SA 4.0)"
      ],
      "metadata": {
        "id": "gDv8iZTem1RO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/mAP_detectores.JPG'>\n",
        "\n",
        "**Figura 6.** Métrica de desempeño (mAP, mean Average Precision) de diferentes algoritmos usando el conjunto de datos COCO"
      ],
      "metadata": {
        "id": "UAR-Fp3JxNNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Campos de aplicación\n",
        "\n",
        "###1. Salud\n",
        "<img src ='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/muestras_sangre.JPG'>\n",
        "\n",
        "###2. Vehículo autónomos (*self-driving cars*)\n",
        "###3. Seguridad y vigilancia\n",
        "###4. Monitoreo de vida silvestre\n",
        "<img src ='https://raw.githubusercontent.com/levc17/ML-tarea4-YOLO/main/ClassifyMe_YOLOv2.jpg'>\n",
        "\n",
        "###5. Usos militares\n"
      ],
      "metadata": {
        "id": "AluiLPJfhUyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Mensaje del uno de los creadores del algoritmo original\n",
        "\n",
        "\"*I have a lot of hope that most of the people using computer vision are just doing happy, good stuff with it, like\n",
        "counting the number of zebras in a national park, or\n",
        "tracking their cat as it wanders around their house. But\n",
        "computer vision is already being put to questionable use and\n",
        "as researchers we have a responsibility to at least consider\n",
        "the harm our work might be doing and think of ways to mitigate it. We owe the world that much.*\" Redmon y Farhadi (2018)."
      ],
      "metadata": {
        "id": "2cc7WnktoMvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Referencias\n",
        "\n",
        "**Artículos**\n",
        "\n",
        "Falzon, G., Lawson, C., Cheung, K. W., Vernes, K., Ballard, G. A., Fleming, P. J., ... & Meek, P. D. (2019). ClassifyMe: a field-scouting software for the identification of wildlife in camera trap images. Animals, 10(1), 58.\n",
        "\n",
        "Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 779-788).\n",
        "\n",
        "Redmon, J., & Farhadi, A. (2018). Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767.\n",
        "\n",
        "\n",
        "**Blogs/páginas web consultadas**\n",
        "\n",
        "https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e\n",
        "\n",
        "https://medium.com/analytics-vidhya/object-detection-algorithm-yolo-v5-architecture-89e0a35472ef\n",
        "\n",
        "\n",
        "https://medium.com/nerd-for-tech/yolo-you-only-look-once-65ea86104c51\n",
        "\n"
      ],
      "metadata": {
        "id": "KCU1ZZuvkDD-"
      }
    }
  ]
}